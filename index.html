<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>æ‹ç…§è¨ˆæ•¸å·¥å…·</title>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.22.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>

  <style>
    body {
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI",
        sans-serif;
      background: #0f172a;
      color: #e5e7eb;
      margin: 0;
      padding: 16px;
      text-align: center;
    }
    button, input {
      margin: 6px;
      padding: 10px 14px;
      font-size: 16px;
      border-radius: 8px;
      border: none;
    }
    button {
      background: #22c55e;
      font-weight: bold;
    }
    button:disabled {
      background: #475569;
    }
    canvas {
      max-width: 100%;
      margin-top: 12px;
      border-radius: 12px;
      background: #020617;
    }
    #result {
      margin-top: 10px;
      font-size: 16px;
    }
  </style>
</head>

<body>
  <h2>ğŸ“¸ æ‹ç…§è¨ˆæ•¸å·¥å…·</h2>

  <input type="file" accept="image/*" id="fileInput">
  <input type="file" accept="image/*" capture="environment" id="cameraInput">

  <br>
  <button id="countBtn" disabled>â–¶ é–‹å§‹è¨ˆæ•¸</button>

  <div id="result">åˆå§‹åŒ–ä¸­â€¦</div>
  <canvas id="canvas"></canvas>

<script>
const fileInput = document.getElementById("fileInput");
const cameraInput = document.getElementById("cameraInput");
const btn = document.getElementById("countBtn");
const result = document.getElementById("result");
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

let img = new Image();
let model = null;

/* ===== åˆå§‹åŒ– AIï¼ˆé—œéµï¼‰===== */
async function initAI() {
  try {
    result.textContent = "â³ åˆå§‹åŒ– TensorFlowâ€¦";
    await tf.ready();

    await tf.setBackend("webgl");
    console.log("backend:", tf.getBackend());

    result.textContent = "â³ è¼‰å…¥ AI æ¨¡å‹â€¦";
    model = await cocoSsd.load();

    result.textContent = "âœ… æ¨¡å‹å·²å°±ç·’ï¼Œè«‹è¼‰å…¥åœ–ç‰‡";
    btn.disabled = false;
  } catch (e) {
    console.error(e);
    alert("AI åˆå§‹åŒ–å¤±æ•—");
  }
}

window.addEventListener("load", initAI);

/* ===== è¼‰å…¥åœ–ç‰‡ ===== */
function loadImage(file) {
  const reader = new FileReader();
  reader.onload = () => {
    img.onload = () => {
      canvas.width = img.width;
      canvas.height = img.height;
      ctx.drawImage(img, 0, 0);
      result.textContent = "ğŸ“· åœ–ç‰‡å·²è¼‰å…¥ï¼Œå¯é–‹å§‹è¨ˆæ•¸";
    };
    img.src = reader.result;
  };
  reader.readAsDataURL(file);
}

fileInput.onchange = e => e.target.files[0] && loadImage(e.target.files[0]);
cameraInput.onchange = e => e.target.files[0] && loadImage(e.target.files[0]);

/* ===== é–‹å§‹è¨ˆæ•¸ï¼ˆä¸€å®šæœ‰åæ‡‰ï¼‰===== */
btn.onclick = async () => {
  alert("â–¶ å·²é»æ“Šé–‹å§‹è¨ˆæ•¸");   // â† å¼·åˆ¶å¯è¦–å›é¥‹

  if (!model) {
    alert("æ¨¡å‹å°šæœªå°±ç·’");
    return;
  }

  if (!img.complete) {
    alert("å°šæœªè¼‰å…¥åœ–ç‰‡");
    return;
  }

  result.textContent = "ğŸ” AI åˆ†æä¸­â€¦ï¼ˆè«‹ç¨å€™ï¼‰";

  ctx.drawImage(img, 0, 0);

  try {
    const predictions = await model.detect(img);

    let count = 0;
    predictions.forEach(p => {
      const [x, y, w, h] = p.bbox;
      ctx.strokeStyle = "#22c55e";
      ctx.lineWidth = 3;
      ctx.strokeRect(x, y, w, h);
      count++;
    });

    result.textContent = `ğŸ¯ åµæ¸¬åˆ° ${count} å€‹ç‰©ä»¶`;
  } catch (e) {
    console.error(e);
    alert("detect ç™¼ç”ŸéŒ¯èª¤");
  }
};
</script>
</body>
</html>
